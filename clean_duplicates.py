import os
import hashlib
from pathlib import Path
from collections import defaultdict
from app import app, db
from models import Details, ImageRecord

# è®¾ç½®å›¾ç‰‡ç›®å½•
IMAGE_FOLDER = Path("static/images")


def get_md5(file_path):
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception as e:
        print(f"[ERROR] è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None


def clean_duplicate_images():
    print("å¼€å§‹æ‰«æå›¾ç‰‡ç›®å½•å»é‡...")
    hash_map = defaultdict(list)

    # éå†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    for file in IMAGE_FOLDER.glob("*.*"):
        if file.is_file():
            file_hash = get_md5(file)
            if file_hash:
                hash_map[file_hash].append(file)

    removed_count = 0
    with app.app_context():
        for file_hash, files in hash_map.items():
            if len(files) <= 1:
                continue  # æ— é‡å¤

            # æ’åºï¼Œä¿ç•™æ–‡ä»¶åæœ€çŸ­çš„ï¼ˆå¦‚æœ‰å¤šä¸ªæœ€çŸ­ï¼Œä¿ç•™æœ€å…ˆçš„ï¼‰
            files.sort(key=lambda f: (len(f.name), f.name))
            keep = files[0]
            delete_list = files[1:]

            for f in delete_list:
                try:
                    os.remove(f)
                    removed_count += 1
                    print(f"ğŸ—‘ åˆ é™¤é‡å¤æ–‡ä»¶: {f}")

                    # æ¸…ç†æ•°æ®åº“ä¸­å¼•ç”¨è¿™ä¸ªæ–‡ä»¶çš„è·¯å¾„
                    records = Details.query.filter_by(local_image_path=str(f)).all()
                    for r in records:
                        r.local_image_path = None

                    ImageRecord.query.filter_by(local_path=str(f)).delete()

                except Exception as e:
                    print(f"[ERROR] åˆ é™¤å¤±è´¥: {f} - {e}")

        db.session.commit()
    print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤é‡å¤æ–‡ä»¶ {removed_count} ä¸ª")
